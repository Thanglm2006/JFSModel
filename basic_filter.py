import pandas as pd
import requests
import json
import math
from tqdm import tqdm

# --- C·∫§U H√åNH ---
INPUT_FILE = ["content1_labeled", "content2_labeled", "content3_labeled", "data_content1_labeled"]
MODEL = "qwen:4b"  # ƒê·∫£m b·∫£o b·∫°n ƒë√£ pull model n√†y
BATCH_SIZE = 30  # K√≠ch th∆∞·ªõc l√¥


def extract_json_from_text(text):
    """
    H√†m ph·ª• tr·ª£: C·ªë g·∫Øng t√¨m v√† c·∫Øt chu·ªói JSON h·ª£p l·ªá t·ª´ ph·∫£n h·ªìi c·ªßa AI
    n·∫øu AI c√≥ l·ª° chat th√™m (VD: "Here is your json: [...]")
    """
    try:
        # T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu c·ªßa m·∫£ng JSON '[' v√† k·∫øt th√∫c ']'
        start = text.find('[')
        end = text.rfind(']') + 1

        if start != -1 and end != -1:
            json_str = text[start:end]
            return json.loads(json_str)
        return []
    except Exception:
        return []


def analyze_batch(texts_list, start_id_offset):
    """
    X·ª≠ l√Ω m·ªôt l√¥ b√†i ƒëƒÉng.
    start_id_offset: ID b·∫Øt ƒë·∫ßu ƒë·ªÉ g√°n cho b√†i vi·∫øt trong l√¥ n√†y (ƒë·ªÉ mapping ng∆∞·ª£c l·∫°i).
    """
    if not texts_list:
        return {}

    # 1. T·∫°o chu·ªói input v·ªõi ID c·ª• th·ªÉ cho t·ª´ng b√†i
    # ID n√†y ch·ªâ d√πng t·∫°m trong prompt ƒë·ªÉ AI bi·∫øt b√†i n√†o l√† b√†i n√†o
    prompt_content = ""
    id_map = []  # L∆∞u danh s√°ch ID trong l√¥ n√†y ƒë·ªÉ ki·ªÉm tra sau

    for i, text in enumerate(texts_list):
        current_id = start_id_offset + i
        id_map.append(current_id)
        # L√†m s·∫°ch text m·ªôt ch√∫t ƒë·ªÉ tr√°nh ph√° v·ª° prompt (x√≥a xu·ªëng d√≤ng th·ª´a)
        clean_text = str(text).replace('\n', ' ').replace('"', "'")[:500]  # C·∫Øt 500 k√Ω t·ª± ƒë·ªÉ ti·∫øt ki·ªám token
        prompt_content += f"ID_{current_id}: {clean_text}\n"

    # 2. Prompt Y√™u c·∫ßu tr·∫£ v·ªÅ ID
    prompt = f"""
    B·∫°n l√† AI ph√¢n lo·∫°i tin tuy·ªÉn d·ª•ng.

    DANH S√ÅCH B√ÄI ƒêƒÇNG:
    {prompt_content}

    Y√äU C·∫¶U:
    - Ph√¢n lo·∫°i t·ª´ng b√†i ƒëƒÉng theo ID t∆∞∆°ng ·ª©ng.
    - Category ch·ªâ ch·ªçn: "RECRUITMENT" (Tuy·ªÉn d·ª•ng), "JOB_SEEKER" (T√¨m vi·ªác), "SPAM_ADS" (R√°c/QC).
    - Tr·∫£ v·ªÅ k·∫øt qu·∫£ d·∫°ng JSON Array. B·∫Øt bu·ªôc ph·∫£i gi·ªØ ƒë√∫ng ID ƒë√£ cung c·∫•p (V√≠ d·ª•: ID_{start_id_offset}).

    OUTPUT FORMAT (JSON ONLY):
    [
      {{"id": "ID_{start_id_offset}", "category": "RECRUITMENT"}},
      {{"id": "ID_{start_id_offset + 1}", "category": "SPAM_ADS"}}
    ]
    """

    try:
        response = requests.post('http://localhost:11434/api/generate', json={
            "model": MODEL,
            "prompt": prompt,
            "format": "json",
            "stream": False,
            "options": {
                "temperature": 0.0,
                "num_ctx": 4096
            },
            "keep_alive": "10m"
        })

        response_text = response.json()['response']

        # D√πng h√†m tr√≠ch xu·∫•t an to√†n
        json_data = extract_json_from_text(response_text)

        # 3. CHUY·ªÇN ƒê·ªîI K·∫æT QU·∫¢ V·ªÄ D·∫†NG DICTIONARY {ID: CATEGORY}
        # ƒêi·ªÅu n√†y gi√∫p ta map ch√≠nh x√°c 1-1, b·∫•t ch·∫•p th·ª© t·ª± AI tr·∫£ v·ªÅ
        result_map = {}
        for item in json_data:
            # L·∫•y s·ªë t·ª´ chu·ªói "ID_123" -> 123
            try:
                raw_id = item.get('id', '')
                # N·∫øu AI tr·∫£ v·ªÅ s·ªë nguy√™n (123) ho·∫∑c chu·ªói ("ID_123")
                if isinstance(raw_id, int):
                    idx = raw_id
                else:
                    idx = int(raw_id.replace("ID_", ""))

                result_map[idx] = item.get('category', 'UNKNOWN')
            except ValueError:
                continue

        return result_map

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω l√¥: {e}")
        return {}


def main():
    print(f"üöÄ ƒêang ch·∫°y model: {MODEL} | BATCH SIZE = {BATCH_SIZE}")

    for file_name in INPUT_FILE:
        full_path = file_name + ".csv"
        try:
            df = pd.read_csv(full_path)
            # T·∫°o b·∫£n sao v√† reset index ƒë·ªÉ ƒë·∫£m b·∫£o index ch·∫°y t·ª´ 0 -> n
            df_process = df.copy().reset_index(drop=True)
            print(f"üìÇ ƒê√£ t·∫£i: {full_path} | {len(df_process)} d√≤ng")
        except FileNotFoundError:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y: {full_path}")
            continue

        col_name = 'content' if 'content' in df.columns else df.columns[0]

        # Th√™m c·ªôt k·∫øt qu·∫£ m·∫∑c ƒë·ªãnh
        df_process['ai_category'] = 'PENDING'

        all_texts = df_process[col_name].astype(str).tolist()
        num_batches = math.ceil(len(all_texts) / BATCH_SIZE)

        # --- V√íNG L·∫∂P BATCH ---
        for i in tqdm(range(num_batches), desc=f"X·ª≠ l√Ω {file_name}"):

            start_idx = i * BATCH_SIZE
            end_idx = min((i + 1) * BATCH_SIZE, len(all_texts))

            current_batch_texts = all_texts[start_idx:end_idx]

            # G·ªåI H√ÄM X·ª¨ L√ù (Truy·ªÅn index b·∫Øt ƒë·∫ßu ƒë·ªÉ l√†m ID)
            # start_idx ch√≠nh l√† ID c·ªßa d√≤ng ƒë·∫ßu ti√™n trong l√¥ n√†y
            batch_results_map = analyze_batch(current_batch_texts, start_id_offset=start_idx)

            # C·∫¨P NH·∫¨T DATAFRAME D·ª∞A TR√äN ID MAP
            # Duy·ªát qua c√°c ID trong l√¥ hi·ªán t·∫°i
            for row_idx in range(start_idx, end_idx):
                # N·∫øu ID n√†y c√≥ trong k·∫øt qu·∫£ tr·∫£ v·ªÅ c·ªßa AI
                if row_idx in batch_results_map:
                    df_process.at[row_idx, 'ai_category'] = batch_results_map[row_idx]
                else:
                    # N·∫øu AI b·ªè s√≥t b√†i n√†y, ƒë√°nh d·∫•u l·ªói ho·∫∑c UNKNOWN
                    df_process.at[row_idx, 'ai_category'] = 'ERROR_MISSING'

        # --- L∆ØU K·∫æT QU·∫¢ ---
        if not df_process.empty:
            # L·ªçc k·∫øt qu·∫£
            final_recruitment_df = df_process[df_process['ai_category'] == 'RECRUITMENT'].copy()

            print(f"\n‚úÖ Ho√†n th√†nh file: {file_name}")
            print(f"- T·ªïng: {len(df_process)}")
            print(f"- Tuy·ªÉn d·ª•ng: {len(final_recruitment_df)}")
            print(f"- L·ªói/Spam: {len(df_process) - len(final_recruitment_df)}")

            output_path = file_name + "_batched_classified.csv"
            final_recruitment_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"üíæ ƒê√£ l∆∞u: {output_path}\n")


if __name__ == "__main__":
    main()