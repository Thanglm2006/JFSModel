import re
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import emoji

# --- Cáº¤U HÃŒNH ---
# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a Model 1 (Model phÃ¢n loáº¡i RÃ¡c/Tuyá»ƒn dá»¥ng)
MODEL_PATH = "./models/step1_mdeberta"  # Sá»­a Ä‘Æ°á»ng dáº«n nÃ y náº¿u báº¡n lÆ°u tÃªn khÃ¡c

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Running on: {device}")

# 1. LOAD MODEL
try:
    loaded_tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    loaded_model.to(device)
    loaded_model.eval()
    print(f"âœ… ÄÃ£ load Model 1 thÃ nh cÃ´ng tá»«: {MODEL_PATH}")
except Exception as e:
    print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y model táº¡i '{MODEL_PATH}'.\nHÃ£y kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n.")
    exit()


def normalize_text(text):
    # HÃ m chuáº©n hÃ³a giá»‘ng há»‡t lÃºc train Ä‘á»ƒ Ä‘áº£m báº£o model hiá»ƒu Ä‘Ãºng
    if not isinstance(text, str):
        return str(text) if text is not None else ""

    # Chuáº©n hÃ³a thá»i gian/lÆ°Æ¡ng
    text = re.sub(r'[\/\\]\s*(\d*h|giá»|tiáº¿ng)', ' má»™t giá» ', text, flags=re.IGNORECASE)
    text = re.sub(r'[\/\\]\s*(ngÃ y|day)', ' má»™t ngÃ y ', text, flags=re.IGNORECASE)
    text = re.sub(r'[\/\\]\s*(thÃ¡ng|month)', ' má»™t thÃ¡ng ', text, flags=re.IGNORECASE)

    # Chuáº©n hÃ³a tiá»n
    text = re.sub(r'\b(\d+)\s*(k|ka|xu)\b', r'\1 nghÃ¬n', text, flags=re.IGNORECASE)
    text = re.sub(r'\b(\d+)\s*(tr|triá»‡u|cá»§|m)\b', r'\1 triá»‡u', text, flags=re.IGNORECASE)

    # Demojize
    return emoji.demojize(text, language='alias')


def predict_is_job(text):
    # Chuáº©n hÃ³a trÆ°á»›c khi Ä‘Æ°a vÃ o model
    clean_text = normalize_text(text)

    inputs = loaded_tokenizer(
        clean_text,
        return_tensors="pt",
        truncation=True,
        max_length=512,
        padding=True
    ).to(device)

    with torch.no_grad():
        outputs = loaded_model(**inputs)

    logits = outputs.logits
    probs = F.softmax(logits, dim=-1)  # Chuyá»ƒn sang xÃ¡c suáº¥t %

    pred_label_idx = torch.argmax(probs, dim=1).item()
    confidence = probs[0][pred_label_idx].item()

    # --- NHÃƒN Cá»¦A MODEL 1 ---
    # 0: RÃ¡c, Quáº£ng cÃ¡o, TÃ¬m viá»‡c
    # 1: BÃ i Tuyá»ƒn dá»¥ng (Ká»ƒ cáº£ lá»«a Ä‘áº£o)
    label_map = {
        0: "ğŸ—‘ï¸ RÃC/SPAM/TÃŒM VIá»†C (NON-JOB)",
        1: "ğŸ“¢ BÃ€I TUYá»‚N Dá»¤NG (JOB)"
    }

    return label_map[pred_label_idx], confidence, probs[0].tolist()


# --- Dá»® LIá»†U TEST ---
# Bao gá»“m Ä‘á»§ cÃ¡c trÆ°á»ng há»£p Ä‘á»ƒ kiá»ƒm tra Ä‘á»™ thÃ´ng minh cá»§a model
test_texts = [
    # Case 1: Tuyá»ƒn dá»¥ng uy tÃ­n (Mong Ä‘á»£i: JOB)
    "Highlands Coffee tuyá»ƒn nhÃ¢n viÃªn phá»¥c vá»¥, lÆ°Æ¡ng 25k/h, lÃ m táº¡i Háº£i ChÃ¢u.",
    "cáº§n nhÃ¢n viÃªn phá»¥c vá»¥",

    # Case 2: Tuyá»ƒn dá»¥ng lá»«a Ä‘áº£o (Mong Ä‘á»£i: JOB - VÃ¬ model nÃ y chá»‰ lá»c rÃ¡c, model 2 má»›i check scam)
    "Tuyá»ƒn nhÃ¢n viÃªn xÃ¢u háº¡t táº¡i nhÃ , lÆ°Æ¡ng 500k/ngÃ y, khÃ´ng cáº§n cá»c.",

    # Case 3: NgÆ°á»i tÃ¬m viá»‡c (Mong Ä‘á»£i: NON-JOB)
    "Em lÃ  sinh viÃªn nÄƒm nháº¥t, cáº§n tÃ¬m viá»‡c lÃ m thÃªm ca tá»‘i áº¡. Ai cÃ³ ib em vá»›i.",
    "em 2k3 Ä‘ang kiáº¿m cÃ´ng viá»‡c ca chiá»u áº¡!",
    "em tÃ¬m cv phá»¥ há»“",
    # Case 4: Quáº£ng cÃ¡o bÃ¡n hÃ ng (Mong Ä‘á»£i: NON-JOB)
    "Thanh lÃ½ lÃ´ quáº§n Ã¡o giÃ¡ ráº», ship toÃ n quá»‘c. Máº¡i dÃ´ máº¡i dÃ´ ğŸ“£ğŸ“£",

    # Case 5: Spam tÃ i chÃ­nh/Cho vay (Mong Ä‘á»£i: NON-JOB)
    "Há»— trá»£ vay vá»‘n sinh viÃªn lÃ£i suáº¥t tháº¥p, giáº£i ngÃ¢n trong ngÃ y.",

    # Case 6: Tin rÃ¡c/TÃ¢m sá»± (Mong Ä‘á»£i: NON-JOB)
    "Buá»“n quÃ¡ cÃ³ ai Ä‘i cafe nÃ³i chuyá»‡n cho vui khÃ´ng áº¡?",
    "....",
    "okok"
]

print("\n" + "=" * 50)
print("--- Káº¾T QUáº¢ TEST MODEL 1 (FILTER) ---")
print("=" * 50)

for t in test_texts:
    label, conf, all_probs = predict_is_job(t)

    print(f"ğŸ“ Text: {t}")
    print(f"ğŸ¯ Káº¿t quáº£: {label}")
    print(f"ğŸ“Š Äá»™ tin cáº­y: {conf:.2%}")
    print(f"ğŸ“‰ Chi tiáº¿t: [RÃ¡c: {all_probs[0]:.2%}, Tuyá»ƒn dá»¥ng: {all_probs[1]:.2%}]")
    print("-" * 50)